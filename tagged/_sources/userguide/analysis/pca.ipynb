{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34eb978f",
   "metadata": {},
   "source": [
    "# Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c55662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spectrochempy as scp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02110409",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Introduction\n",
    "\n",
    "PCA (standing for Principal Component Analysis) is one of the most popular\n",
    "method for dimensionality reduction by factorising a dataset $X$ into score ($S$) and\n",
    "loading ($L^T$) matrices of a limited number of components and minimize the error $E$:\n",
    "$$ X = S L^T + E $$\n",
    "These matrices are such that the product of the first column of $S$ - the score vector $s_1$ -\n",
    "by the first line of $L^T$ - the loading vector $l_1$ - are those that best explain the variance\n",
    "of the dataset. These score and loading vectors are together called the ‘first component’. The\n",
    "second component best explain the remaining variance, etc...\n",
    "\n",
    "The implementation of PCA in spectrochempy is based on the [Scikit-Learn](https://scikit-learn.org/)\n",
    "implementation of [PCA](https://scikit-learn.org/stable/modules/decomposition.html#principal-component-analysis-pca).\n",
    "with similar methods and attributes on the one hands, and some that are specific to spectrochempy.\n",
    "\n",
    "## Loading of the dataset\n",
    "Here we show how PCA is implemented in Scpy on a dataset corresponding to a HPLC-DAD run,\n",
    "from Jaumot et al. Chemolab, 76 (2005), pp. 101-110 and Jaumot et al. Chemolab, 140 (2015)\n",
    "pp. 1-12. This dataset (and others) can be loaded from the [Multivariate Curve Resolution\n",
    "Homepage](https://mcrals.wordpress.com/download/example-data-sets). For the user convenience,\n",
    "this dataset is present in the 'datadir' of spectrochempy in 'als2004dataset.MAT' and can be\n",
    "read as follows in Scpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcca7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = scp.read_matlab(\"matlabdata/als2004dataset.MAT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88691209",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The .mat file contains 6 matrices which are thus returned in A as a list of 6\n",
    "NDDatasets. We print the names and dimensions of these datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9d7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in A:\n",
    "    print(f\"{a.name} : {a.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3021425a",
   "metadata": {},
   "source": [
    "In this tutorial, we are first interested in the dataset named ('m1') that contains\n",
    "a singleHPLC-DAD run(s).\n",
    "As usual, the rows correspond to the 'time axis' of the HPLC run(s), and the columns\n",
    "to the 'wavelength' axis of the UV spectra.\n",
    "\n",
    "Let's name it `X` (as in the matrix equation above), display its content and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c902a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = A[-1]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22c6f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = X.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33729ec6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "This original matrix ('m1') does not contain information as to the actual elution time, wavelength,\n",
    "and data units. Hence, the resulting NDDataset has no coordinates and on the plot,\n",
    "only the matrix line and row # indexes are indicated.\n",
    "For the clarity of the tutorial, we add: (i) a proper title to the data, (ii)\n",
    "the default coordinates (index) do the NDDataset and (iii) a proper name for these\n",
    "coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d30b03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.title = \"absorbance\"\n",
    "X.y = scp.Coord.arange(51, title=\"elution time\", labels=[str(i) for i in range(51)])\n",
    "X.x = scp.Coord.arange(96, title=\"wavelength\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83b8a94",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "From now on, these names will be taken into account by Scpy in the plots as well as\n",
    "in the analysis treatments (PCA, EFA, MCR-ALS ...). For instance to plot X as a surface:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d868d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = X.plot_surface(linewidth=0.0, ccount=100, figsize=(10, 5), autolayout=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf1ea7e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Running a PCA\n",
    "First, we create a PCA object with default parameters and we compute the components with the fit() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0da2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = scp.PCA()\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dd9c41",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The default number of components is given by min(X.shape). As often in spectroscopy\n",
    "the number of observations/spectra is lower that the number of wavelength/features, the number of components\n",
    "often equals the number of spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9f8a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172673a7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "As the main purpose of PCA is dimensionality reduction, we generally limit the PCA to a limited number of components.\n",
    "This can be done by either reseting the number of components of an existing object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components = 8\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2620fefe",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Or directly by creating a PCA instance with the desired number of components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b4b0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = scp.PCA(n_components=8)\n",
    "pca.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aa3fa5",
   "metadata": {},
   "source": [
    "The choice of the optimum number of components to describe a dataset is always a delicate matter. It can be based on:\n",
    "- examination of the explained variance\n",
    "- examination of the scores and loadings\n",
    "- comparison of the experimental vs. reconstructed dataset\n",
    "\n",
    "The so-called figures of merit of the PCA can be obtained with the `printev()` method:\n",
    "pca.printev()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95db1a06",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The data of the two last columns are stored in the `PCA.explained_variance_ratio' and\n",
    "`PCA.cumulative_explained_variance' attributes. They can be plotted directly as a scree plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0139d2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pca.screeplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4a48d1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The number of significant PC's is clearly larger or equal to 2. It is, however,\n",
    "difficult to determine whether\n",
    "it should be set to 3 or 4...  Let's look at the score and loading matrices.\n",
    "\n",
    "The scores and loadings can be obtained using the `scores` and `loadings` PCA attribute or\n",
    "obtained by the Scikit-Learn-like methods/attributes `pca.transform()` and `pca.components`,\n",
    "respectively.\n",
    "\n",
    "Scores and Loadings can be plotted using the usual plot() method, with prior transpositon\n",
    "for the scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd940cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pca.scores.T.plot()\n",
    "_ = pca.loadings.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f63e00",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Examination of the plots above indicate that the 4th component has a structured,\n",
    "nonrandom loading and score, while they are random fopr the next ones. Hence, one could\n",
    "reasonably assume that 4 PC are enough to correctly account of the dataset.\n",
    "\n",
    "Another possibility can be a visual comparison of the modeled dataset $\\hat{X} = S L^T $,\n",
    "the original dataset $X$ and the resitua,s $E = X - \\hat{X}$. This can be done using\n",
    "the `plotmerit()` method which plots both $X$, $\\hat{X}$ (in dotted lines) and the residuals (in red):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5c745b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = scp.PCA(n_components=4)\n",
    "pca.fit(X)\n",
    "_ = pca.plotmerit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e848d0e",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "The number of spectra can be limited by the `nb_traces` attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a38bbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pca.plotmerit(nb_traces=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69804b3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "and if needed both datasets can be shifted using the `offset` attribute (in percet of the fullscale):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6beb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.plotmerit(nb_traces=5, offset=100.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6388fab9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Score plots can be used to see the projection of each observation/spectrum\n",
    "onto the span of the principal components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ec40e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pca.scoreplot(1, 2, show_labels=True, labels_every=5)\n",
    "_ = pca.scoreplot(1, 2, 3)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent",
   "notebook_metadata_filter": "all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
